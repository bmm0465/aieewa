// ê¸°ë³¸ PDF íŒŒì¼ë“¤ì„ Supabaseì— ë¯¸ë¦¬ ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
// ë¡œì»¬ì—ì„œ í•œ ë²ˆ ì‹¤í–‰í•˜ì—¬ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env.local íŒŒì¼)
require('dotenv').config({ path: require('path').join(__dirname, '..', '.env.local') })

const { readdir, readFile } = require('fs/promises')
const { join } = require('path')
const { existsSync } = require('fs')
// pdf-parse import - ì™„ì „íˆ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
const pdfParseModule = require('pdf-parse')
const pdfParse = (buffer, options = {}) => {
  return new Promise((resolve, reject) => {
    pdfParseModule(buffer, options)
      .then(resolve)
      .catch(reject)
  })
}
const { createClient } = require('@supabase/supabase-js')

// í™˜ê²½ ë³€ìˆ˜ í™•ì¸
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY

console.log('í™˜ê²½ ë³€ìˆ˜ í™•ì¸:')
console.log('SUPABASE_URL ì¡´ì¬:', !!supabaseUrl)
console.log('SERVICE_ROLE_KEY ì¡´ì¬:', !!supabaseKey)

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  console.error('')
  console.error('ğŸ“‹ ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:')
  console.error('   - NEXT_PUBLIC_SUPABASE_URL')
  console.error('   - SUPABASE_SERVICE_ROLE_KEY')
  console.error('')
  console.error('ğŸ’¡ í•´ê²° ë°©ë²•:')
  console.error('   1. .env.local íŒŒì¼ì„ ìƒì„±í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”')
  console.error('   2. ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•œ í›„ ì‹¤í–‰í•˜ì„¸ìš”:')
  console.error('      $env:NEXT_PUBLIC_SUPABASE_URL="your_url"; $env:SUPABASE_SERVICE_ROLE_KEY="your_key"; npm run seed-pdfs')
  console.error('')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseKey)

// ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°
function splitText(text, chunkSize = 1000, chunkOverlap = 200) {
  const chunks = []
  let start = 0
  
  while (start < text.length) {
    const end = Math.min(start + chunkSize, text.length)
    let chunk = text.slice(start, end)
    
    if (end < text.length) {
      const lastSentenceEnd = chunk.lastIndexOf('.')
      const lastNewline = chunk.lastIndexOf('\n')
      const lastBreak = Math.max(lastSentenceEnd, lastNewline)
      
      if (lastBreak > start + chunkSize * 0.5) {
        chunk = chunk.slice(0, lastBreak + 1)
      }
    }
    
    chunks.push(chunk.trim())
    start += chunk.length - chunkOverlap
    
    if (start >= text.length) break
    if (chunk.length <= chunkOverlap) start += chunkSize
  }
  
  return chunks.filter(chunk => chunk.length > 0)
}

async function seedDefaultPdfs() {
  try {
    console.log('ê¸°ë³¸ PDF íŒŒì¼ ì‹œë“œ ì‹œì‘...')
    
    const pdfFolderPath = join(process.cwd(), 'pdf')
    
    if (!existsSync(pdfFolderPath)) {
      console.error('pdf í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      return
    }

    const files = await readdir(pdfFolderPath)
    const pdfFiles = files.filter(file => file.toLowerCase().endsWith('.pdf'))
    
    console.log(`ë°œê²¬ëœ PDF íŒŒì¼: ${pdfFiles.length}ê°œ`)

    for (const filename of pdfFiles) {
      try {
        console.log(`ì²˜ë¦¬ ì¤‘: ${filename}`)
        
        const filePath = join(pdfFolderPath, filename)
        const fileBuffer = await readFile(filePath)
        
        const pdfData = await pdfParse(fileBuffer, {})
        const text = pdfData.text

        if (!text || text.trim().length === 0) {
          console.warn(`${filename}: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`)
          continue
        }

        const chunks = splitText(text, 1000, 200)
        console.log(`${filename}: ${chunks.length}ê°œ ì²­í¬ ìƒì„±`)

        // ë¬¸ì„œ ì •ë³´ ì €ì¥
        const { data: docData, error: docError } = await supabase
          .from('documents')
          .upsert({
            filename: `pdf/${filename}`,
            file_size: fileBuffer.length,
            text_content: text.substring(0, 10000),
            chunk_count: chunks.length,
            upload_time: new Date().toISOString(),
          }, {
            onConflict: 'filename'
          })
          .select()
          .single()

        if (docError) {
          console.error(`${filename} ë¬¸ì„œ ì €ì¥ ì˜¤ë¥˜:`, docError)
          continue
        }

        // ê¸°ì¡´ ì²­í¬ë“¤ ì‚­ì œ
        await supabase
          .from('document_chunks')
          .delete()
          .eq('document_id', docData.id)

        // ì²­í¬ë“¤ ì €ì¥
        const chunksToInsert = chunks.map((chunk, index) => ({
          document_id: docData.id,
          chunk_text: chunk,
          chunk_index: index,
          metadata: {
            source: `pdf/${filename}`,
            chunkIndex: index,
            uploadTime: new Date().toISOString(),
            isDefault: true
          }
        }))

        const { error: chunkError } = await supabase
          .from('document_chunks')
          .insert(chunksToInsert)

        if (chunkError) {
          console.error(`${filename} ì²­í¬ ì €ì¥ ì˜¤ë¥˜:`, chunkError)
        } else {
          console.log(`${filename}: ${chunks.length}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ`)
        }

      } catch (error) {
        console.error(`${filename} ì²˜ë¦¬ ì˜¤ë¥˜:`, error)
      }
    }

    console.log('ê¸°ë³¸ PDF íŒŒì¼ ì‹œë“œ ì™„ë£Œ!')

  } catch (error) {
    console.error('ì‹œë“œ ì‹¤í–‰ ì˜¤ë¥˜:', error)
  }
}

seedDefaultPdfs()
